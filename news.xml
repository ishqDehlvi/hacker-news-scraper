<?xml version='1.0' encoding='utf-8'?>
<news><item><title>Faster substring search with SIMD in Zig</title><url>https://aarol.dev/posts/zig-simd-substr/</url><score>47</score></item><item><title>Vanishing from Hyundaiâ€™s data network</title><url>http://techno-fandom.org/~hobbit/cars/ev/offnet.html</url><score>288</score></item><item><title>Millau Viaduct</title><url>https://www.fosterandpartners.com/projects/millau-viaduct</url><score>56</score></item><item><title>Hand-picked selection of articles on AI fundamentals/concepts</title><url>https://aman.ai/primers/ai/</url><score>19</score></item><item><title>Self-Guaranteeing Promises</title><url>https://stephango.com/self-guarantee</url><score>21</score></item><item><title>Try and</title><url>https://ygdp.yale.edu/phenomena/try-and</url><score>557</score></item><item><title>Generic Containers in C: Safe Division Using Maybe</title><url>https://uecker.codeberg.page/2025-08-10.html</url><score>56</score></item><item><title>Compiling a Lisp: Lambda lifting</title><url>https://bernsteinbear.com/blog/compiling-a-lisp-12/</url><score>124</score></item><item><title>GPT-OSS vs. Qwen3 and a detailed look how things evolved since GPT-2</title><url>https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the</url><score>407</score></item><item><title>GPT-OSS-120B runs on just 8GB VRAM &amp; 64GB+ system RAM</title><url>https://old.reddit.com/r/LocalLLaMA/comments/1mke7ef/120b_runs_awesome_on_just_8gb_vram/</url><score>34</score></item></news>